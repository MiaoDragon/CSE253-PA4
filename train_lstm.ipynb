{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_split_loaders\n",
    "from model import GenericRNN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy\n",
    "config = {'chunk_size':100, 'type_number':93, 'hidden':100, \n",
    "          'learning_rate':0.001, 'early_stop':False, 'increase_limit':3, 'epoch_num':1, 'N':50, 'M':100}\n",
    "\n",
    "def train(config):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "        print(\"CUDA is supported\")\n",
    "    else: # Otherwise, train on the CPU\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "        print(\"CUDA NOT supported\")\n",
    "    \n",
    "    # the size of every chunk\n",
    "    chunk_size = config['chunk_size']\n",
    "    # number of types, it is a constant\n",
    "    type_number = config['type_number']\n",
    "    # number of features in hidden layer\n",
    "    hidden = config['hidden']\n",
    "    # learning rate\n",
    "    learning_rate = config['learning_rate']\n",
    "    # whether we use early stop\n",
    "    early_stop = config['early_stop']\n",
    "    # after validation loss increase how many times do we stop training\n",
    "    increase_limit = config['increase_limit']\n",
    "    # number of epoch\n",
    "    epoch_num = config['epoch_num']\n",
    "    # receive train, validation, test data\n",
    "    train, valid, test, c_to, one_to = create_split_loaders(chunk_size,extras)\n",
    "    # construct network\n",
    "    net = GenericRNN(type_number, hidden, type_number)\n",
    "    net = net.to(computing_device)\n",
    "    # use cross entropy loss\n",
    "    criterion = nn.BCELoss()\n",
    "    # keep tracking of the traininig loss\n",
    "    training_record = []\n",
    "    # keep tracking of the validation loss\n",
    "    validation_record = []\n",
    "    # Using Adam\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    last_valid = float('inf')\n",
    "    best_net = -1\n",
    "    # after how many batches do we record the training loss\n",
    "    N = config['N']\n",
    "    # after how many batches do we examine whether validation loss increase\n",
    "    M = config['M']\n",
    "    # store best loss\n",
    "    best_loss = float('inf')\n",
    "    inresement = 0\n",
    "    for epoch in range(epoch_num):\n",
    "        count = 0\n",
    "        average_loss = 0\n",
    "        for minibatch in train:\n",
    "            count += 1\n",
    "            if minibatch[0].size()[0] != chunk_size:\n",
    "                break\n",
    "            predict_all = torch.zeros(chunk_size, type_number)\n",
    "            target_all = torch.zeros(chunk_size, type_number)\n",
    "            optimizer.zero_grad()\n",
    "            for ii in range(chunk_size):\n",
    "                train_batch = torch.zeros(1, 1, type_number)\n",
    "                train_batch[0] = minibatch[0][ii]\n",
    "                train_batch = train_batch.to(computing_device)\n",
    "                target = minibatch[1][ii]\n",
    "                target = target.to(computing_device)\n",
    "                if ii == 0:\n",
    "                    predict = net.predict(train_batch)\n",
    "                else:\n",
    "                    # teacher forcing\n",
    "                    teacher = torch.ones(1, 1, type_number)\n",
    "                    teacher[0] = minibatch[1][ii - 1]\n",
    "                    teacher = teacher.to(computing_device)\n",
    "                    predict = net.predict(train_batch, teacher)\n",
    "                predict_all[ii] = predict\n",
    "                target_all[ii] = target\n",
    "            # validation and early stop\n",
    "            if early_stop:\n",
    "                if count % M == 0:\n",
    "                    loss_val = 0\n",
    "                    count_val = 0\n",
    "                    for val in valid:\n",
    "                        count_val += 1\n",
    "                        if val[0].size()[0] != chunk_size:\n",
    "                            break\n",
    "                        predict_valid = torch.zeros(chunk_size, type_number)\n",
    "                        target_valid = torch.zeros(chunk_size, type_number)\n",
    "                        for ii in range(chunk_size):\n",
    "                            valid_batch = torch.zeros(1, 1, type_number)\n",
    "                            valid_batch[0] = val[0][ii]\n",
    "                            valid_batch = valid_batch.to(computing_device)\n",
    "                            target = val[1][ii]\n",
    "                            target = target.to(computing_device)\n",
    "                            predict = net.predict(valid_batch)\n",
    "                            predict_valid[ii] = predict\n",
    "                            target_valid[ii] = target\n",
    "                        loss_val += criterion(predict_valid, target_valid)\n",
    "                    loss_val /= count_val\n",
    "                    validation_record.append(loss_val.item())\n",
    "                    print('keep tracking of validation error')\n",
    "                    print(validation_record)\n",
    "                    if loss_val > last_valid:\n",
    "                        increasement += 1\n",
    "                    else:\n",
    "                        increasement = 0\n",
    "                    if loss_val < best_loss:\n",
    "                        best_loss = loss_val\n",
    "                        best_net = copy.deepcopy(net)\n",
    "                    last_valid = loss_val\n",
    "                    if increasement >= increase_limit:\n",
    "                        break\n",
    "            # calculate loss\n",
    "            loss = criterion(predict_all, target_all)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            average_loss += loss.item()\n",
    "            if count % N == 0:\n",
    "                training_record.append(average_loss / N)\n",
    "                average_loss = 0\n",
    "                print('keep tracking of training error:')\n",
    "                print(training_record)\n",
    "#             print(loss.item())\n",
    "        if early_stop:\n",
    "            if increasement >= increase_limit:\n",
    "                break\n",
    "    if early_stop:\n",
    "        net = best_net\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294, 0.04749406479299068]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294, 0.04749406479299068, 0.0449330398440361]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294, 0.04749406479299068, 0.0449330398440361, 0.04638348780572414]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294, 0.04749406479299068, 0.0449330398440361, 0.04638348780572414, 0.044962984174489976]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294, 0.04749406479299068, 0.0449330398440361, 0.04638348780572414, 0.044962984174489976, 0.046081149578094484]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294, 0.04749406479299068, 0.0449330398440361, 0.04638348780572414, 0.044962984174489976, 0.046081149578094484, 0.04653844386339188]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294, 0.04749406479299068, 0.0449330398440361, 0.04638348780572414, 0.044962984174489976, 0.046081149578094484, 0.04653844386339188, 0.042737606093287465]\n",
      "keep tracking of training error:\n",
      "[0.058622940331697466, 0.05302516132593155, 0.04993059240281582, 0.04812738552689552, 0.04519643031060696, 0.045326415672898294, 0.04749406479299068, 0.0449330398440361, 0.04638348780572414, 0.044962984174489976, 0.046081149578094484, 0.04653844386339188, 0.042737606093287465, 0.040164442583918575]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8e44f5f578ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-fe5d412d93b2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0maverage_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
