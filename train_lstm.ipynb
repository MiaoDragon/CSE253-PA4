{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import create_split_loaders\n",
    "from model import GenericRNN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy\n",
    "import os\n",
    "from utility import *\n",
    "\n",
    "config = {'chunk_size':100, 'type_number':93, 'hidden':100, \n",
    "          'learning_rate':0.001, 'early_stop':True, 'increase_limit':3, \n",
    "          'epoch_num':1, 'N':50, 'M':100, 'seed':1, 'model':'LSTM', 'model_path':'model_weights'}\n",
    "\n",
    "def train(config):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "        extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "        print(\"CUDA is supported\")\n",
    "    else: # Otherwise, train on the CPU\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "        extras = False\n",
    "        print(\"CUDA NOT supported\")\n",
    "    \n",
    "    seed = config['seed']\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # the size of every chunk\n",
    "    chunk_size = config['chunk_size']\n",
    "    # number of types, it is a constant\n",
    "    type_number = config['type_number']\n",
    "    # number of features in hidden layer\n",
    "    hidden = config['hidden']\n",
    "    # learning rate\n",
    "    learning_rate = config['learning_rate']\n",
    "    # whether we use early stop\n",
    "    early_stop = config['early_stop']\n",
    "    # after validation loss increase how many times do we stop training\n",
    "    increase_limit = config['increase_limit']\n",
    "    # number of epoch\n",
    "    epoch_num = config['epoch_num']\n",
    "    # receive train, validation, test data\n",
    "    train, valid, test, c_to, one_to = create_split_loaders(chunk_size,extras)\n",
    "    \n",
    "    # construct network\n",
    "    net = GenericRNN(type_number, hidden, type_number, config['model'])\n",
    "    # if model already exists, then load the previous one\n",
    "    if os.path.exists(config['model_path']+'.pkl'):\n",
    "        print('loading previous model...')\n",
    "        load_net_state(net, config['model_path']+'.pkl')\n",
    "    net = net.to(computing_device)\n",
    "    \n",
    "    # use cross entropy loss\n",
    "    criterion = nn.BCELoss()\n",
    "    # keep tracking of the traininig loss\n",
    "    training_record = []\n",
    "    # keep tracking of the validation loss\n",
    "    validation_record = []\n",
    "    \n",
    "    # Using Adam\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    # if model already exists, then load the previous optimizer state\n",
    "    prev_total_loss, prev_avg_minibatch_loss, prev_val_loss = [], [], []\n",
    "    if os.path.exists(config['model_path']+'.pkl'):\n",
    "        print('loading optimizer state...')\n",
    "        load_opt_state(optimizer, config['model_path']+'.pkl')\n",
    "        # notice when saving prev_val_loss, we ignored the first val_loss\n",
    "        prev_total_loss, prev_avg_minibatch_loss, prev_val_loss = load_loss(config['model_path']+'.pkl')\n",
    "    \n",
    "    total_loss = [] + prev_total_loss\n",
    "    avg_minibatch_loss = [] + prev_avg_minibatch_loss\n",
    "    val_loss = [1000000000] + prev_val_loss #assume large error at the begining\n",
    "\n",
    "    last_valid = float('inf')\n",
    "    best_net = -1\n",
    "    # after how many batches do we record the training loss\n",
    "    N = config['N']\n",
    "    # after how many batches do we examine whether validation loss increase\n",
    "    M = config['M']\n",
    "    # store best loss\n",
    "    best_loss = float('inf')\n",
    "    increasement = 0\n",
    "    for epoch in range(epoch_num):\n",
    "        count = 0\n",
    "        average_loss = 0\n",
    "        for minibatch in train:\n",
    "            count += 1\n",
    "            if minibatch[0].size()[0] != chunk_size:\n",
    "                break\n",
    "            predict_all = torch.zeros(chunk_size, type_number)\n",
    "            target_all = torch.zeros(chunk_size, type_number)\n",
    "            optimizer.zero_grad()\n",
    "            for ii in range(chunk_size):\n",
    "                train_batch = torch.zeros(1, 1, type_number)\n",
    "                train_batch[0] = minibatch[0][ii]\n",
    "                train_batch = train_batch.to(computing_device)\n",
    "                target = minibatch[1][ii]\n",
    "                target = target.to(computing_device)\n",
    "                if ii == 0:\n",
    "                    predict = net.predict(train_batch)\n",
    "                else:\n",
    "                    # teacher forcing\n",
    "                    teacher = torch.ones(1, 1, type_number)\n",
    "                    teacher[0] = minibatch[1][ii - 1]\n",
    "                    teacher = teacher.to(computing_device)\n",
    "                    predict = net.predict(train_batch, teacher)\n",
    "                predict_all[ii] = predict\n",
    "                target_all[ii] = target\n",
    "            # calculate loss\n",
    "            loss = criterion(predict_all, target_all)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss.append(loss.item())\n",
    "            average_loss += loss.item()\n",
    "            if count % N == 0:\n",
    "                training_record.append(average_loss / N)\n",
    "                avg_minibatch_loss.append(average_loss / N)\n",
    "                average_loss = 0\n",
    "                print('keep tracking of training error:')\n",
    "                print(training_record)\n",
    "#             print(loss.item())\n",
    "            # validation \n",
    "            if count % M == 0:\n",
    "                with torch.no_grad():\n",
    "                    loss_val = 0\n",
    "                    count_val = 0\n",
    "                    for val in valid:\n",
    "                        count_val += 1\n",
    "                        if val[0].size()[0] != chunk_size:\n",
    "                            break\n",
    "                        predict_valid = torch.zeros(chunk_size, type_number)\n",
    "                        target_valid = torch.zeros(chunk_size, type_number)\n",
    "                        for ii in range(chunk_size):\n",
    "                            valid_batch = torch.zeros(1, 1, type_number)\n",
    "                            valid_batch[0] = val[0][ii]\n",
    "                            valid_batch = valid_batch.to(computing_device)\n",
    "                            target = val[1][ii]\n",
    "                            target = target.to(computing_device)\n",
    "                            predict = net.predict(valid_batch)\n",
    "                            predict_valid[ii] = predict\n",
    "                            target_valid[ii] = target\n",
    "                        loss_val += criterion(predict_valid, target_valid)\n",
    "                    loss_val /= count_val\n",
    "                    val_loss.append(loss_val.item())\n",
    "                    validation_record.append(loss_val.item())\n",
    "                    print('keep tracking of validation error')\n",
    "                    print(validation_record)\n",
    "                    if loss_val < best_loss:\n",
    "                        print('best model is updated')\n",
    "                        best_loss = loss_val\n",
    "                        best_net = copy.deepcopy(net)\n",
    "                save_state(best_net, optimizer, total_loss, avg_minibatch_loss, val_loss[1:], \\\n",
    "                           seed, config['model_path']+'.pkl')\n",
    "                if early_stop:\n",
    "                    if loss_val > last_valid:\n",
    "                        increasement += 1\n",
    "                    else:\n",
    "                        increasement = 0\n",
    "                    last_valid = loss_val\n",
    "                    if increasement >= increase_limit:\n",
    "                        break\n",
    "        if early_stop:\n",
    "            if increasement >= increase_limit:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "keep tracking of training error:\n",
      "[0.058679397851228714]\n",
      "keep tracking of training error:\n",
      "[0.058679397851228714, 0.0533315659314394]\n",
      "keep tracking of validation error\n",
      "[0.052765846252441406]\n",
      "best model is updated\n",
      "keep tracking of training error:\n",
      "[0.058679397851228714, 0.0533315659314394, 0.049992689564824104]\n",
      "keep tracking of training error:\n",
      "[0.058679397851228714, 0.0533315659314394, 0.049992689564824104, 0.0482254733145237]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8e44f5f578ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-f6d62ac84c76>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    133\u001b[0m                             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputing_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                             \u001b[0mpredict_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mtarget_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/48/548/kxu/project_4/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, state_0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# only return the sequential output, discard the hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/48/548/kxu/project_4/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, state_0)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# return the sequence output, hidden state and cell state of last data in sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# convert back to shape (chunk_size, out_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# and do linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
